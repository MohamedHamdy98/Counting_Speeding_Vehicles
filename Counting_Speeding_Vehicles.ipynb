{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96b2ab1a-a701-4bb3-8341-a143981c7e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO, solutions\n",
    "import supervision as sv\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1e9b916-b9d0-4156-901c-5081f4260d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = r'C:\\Users\\Mohamed Hamde\\Data Science\\Computer Vision\\vehicles-2.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8571688-d253-4aa6-9358-2b15a6aa717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bbd2dbed-0fd4-4726-b003-aa95726644c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VideoInfo(width=1920, height=1080, fps=29, total_frames=1275)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_info = sv.VideoInfo.from_video_path(video_path)\n",
    "video_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "588cb821-076e-4aa0-b960-ffd78dd3fe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# track object\n",
    "track = sv.ByteTrack()\n",
    "\n",
    "# bounding box and label objects\n",
    "bounding_box_annotator = sv.BoundingBoxAnnotator()\n",
    "label_annoator = sv.LabelAnnotator()\n",
    "\n",
    "# line zone\n",
    "start_point = sv.Point(170, 800)\n",
    "end_point = sv.Point(1700, 800)\n",
    "line_zone = sv.LineZone(start_point, end_point)\n",
    "line_zone_annotator = sv.LineZoneAnnotator(custom_out_text = 'Number of Cars In', \n",
    "                                           custom_in_text = 'Number of Cars Out', \n",
    "                                           display_in_count=False, display_out_count=False,\n",
    "                                           text_padding = 10, text_scale=1, text_offset=2, color=sv.draw.color.Color(255,0,0))\n",
    "\n",
    "# callbacks\n",
    "def callback(frame: np.ndarray, index:int) -> np.ndarray:\n",
    "    # detections\n",
    "    results = model(frame, verbose=False)[0]\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "    detections = track.update_with_detections(detections = detections[(detections.class_id == 2) | (detections.class_id == 7)])\n",
    "    line_zone.trigger(detections)\n",
    "    \n",
    "    # as data frame\n",
    "    ds_counting = {'count_in':[line_zone.out_count], 'count_out':[line_zone.in_count]}\n",
    "    global df_counting\n",
    "    df_counting = pd.DataFrame(ds_counting)\n",
    "\n",
    "    # speed estimation\n",
    "    prev_center = None\n",
    "    prev_time = None\n",
    "    for box in detections:\n",
    "        x1, y1, x2, y2 = box[0]\n",
    "        track_id = box[4]\n",
    "        center_x = (x1 + x2) / 2 \n",
    "        center_y = (y1 + y2) / 2  \n",
    "        center = (center_x, center_y) \n",
    "        \n",
    "        # Calculate speed if we have a previous center and time\n",
    "        if prev_center is not None:\n",
    "            displacement = abs(center[0] - prev_center[0])  # Assuming tracking along x-axis\n",
    "            time_interval = 1 / video_info.fps  # Time between frames\n",
    "            speed_mps = displacement / time_interval  # Speed in pixels per second (assuming 1 pixel = 1 meter)\n",
    "            speed_kph = speed_mps * 3.6 # Speed in km/h\n",
    "            \n",
    "            font = cv2.FONT_HERSHEY_DUPLEX \n",
    "            x1 = int(x1)\n",
    "            y1 = int(y1)\n",
    "            x2 = int(x2)\n",
    "            y2 = int(y2)\n",
    "            cv2.putText(frame, f\"Speed: {speed_kph:.2f} km/h\", (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "            \n",
    "        # Update previous center and time\n",
    "        prev_center = center  \n",
    "        \n",
    "    # customization input and output cars \n",
    "    font = cv2.FONT_HERSHEY_DUPLEX \n",
    "    cv2.putText(frame, f'Number of Cars Out: {line_zone.in_count}', (500, 550),  font, 1,  (255, 255, 0),  3) \n",
    "    cv2.putText(frame, f'Number of Cars In: {line_zone.out_count}', (1000, 550),  font, 1,  (255, 255, 0),  3)\n",
    "    cv2.putText(frame, 'Line Zone', (170, 780),  font, 1.25,  (255, 255, 0),  3)\n",
    "    \n",
    "    # annotatios\n",
    "    labels = [f'{model.model.names[class_id]}' for class_id in detections.class_id]\n",
    "    annotated_frame = bounding_box_annotator.annotate(scene=frame, detections=detections)\n",
    "    annotated_frame = label_annoator.annotate(scene=annotated_frame, detections=detections, labels=labels)\n",
    "    annotated_frame = line_zone_annotator.annotate(annotated_frame, line_counter=line_zone)\n",
    "\n",
    "    return annotated_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "fe8b4cac-856c-4728-b859-1f6496600e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv.process_video(\n",
    "    source_path = video_path,\n",
    "    target_path = 'sv_counting_speeding_cars.mp4',\n",
    "    callback=callback\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
